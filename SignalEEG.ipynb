{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignalEEG.ipynb",
      "provenance": [],
      "mount_file_id": "1dF9A3DIdp19nX3EhrKhUK7VO11W6oKbh",
      "authorship_tag": "ABX9TyMqnXBPGH/Mv6rkI+nVkCVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachidaMellouli/StagePFE/blob/main/SignalEEG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "y6sFUBJ1Gr--",
        "outputId": "7599650d-734d-4cc2-cc35-0fe8069ec1b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from scipy.stats import mannwhitneyu\n",
        "y_train_test = []\n",
        "init_notebook_mode(connected=True) ## plotly init\n",
        "seed = 123\n",
        "random.seed = seed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_listFN = os.listdir('./drive/MyDrive/DatasetEEG/FN/') ## list of file names in the directory\n",
        "filenames_listFP = os.listdir('./drive/MyDrive/DatasetEEG/FP/') \n",
        "filenames_listFU = os.listdir('./drive/MyDrive/DatasetEEG/FU/') \n",
        "filenames_listNN = os.listdir('./drive/MyDrive/DatasetEEG/NN/') \n",
        "filenames_listNP = os.listdir('./drive/MyDrive/DatasetEEG/NP/') \n",
        "filenames_listNU = os.listdir('./drive/MyDrive/DatasetEEG/NU/') \n",
        "EEG_data = [] ## create an empty df that will hold data from each file"
      ],
      "metadata": {
        "id": "HerrFWQfG2LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(filenames_listFN):\n",
        "    temp_df = pd.read_csv('./drive/MyDrive/DatasetEEG/FN/' + file_name) ## read from the file to df\n",
        "    EEG_data.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append(1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QLqJkZoG769",
        "outputId": "031f8e49-5956-4389-e7f0-bcde97722510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4336/4336 [01:57<00:00, 36.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(filenames_listFP):\n",
        "    temp_df = pd.read_csv('./drive/MyDrive/DatasetEEG/FP/' + file_name) ## read from the file to df\n",
        "    EEG_data.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append(2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BapaBV5uHDWO",
        "outputId": "d2a930df-c9a9-4209-a6b3-62110b91e7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4371/4371 [01:43<00:00, 42.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(filenames_listFU):\n",
        "    temp_df = pd.read_csv('./drive/MyDrive/DatasetEEG/FU/' + file_name) ## read from the file to df\n",
        "    EEG_data.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append(3) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn6au1r3HKrg",
        "outputId": "96818372-970a-4a78-8ced-c9637c5a0000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4242/4242 [01:49<00:00, 38.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(filenames_listNN):\n",
        "    temp_df = pd.read_csv('./drive/MyDrive/DatasetEEG/NN/' + file_name) ## read from the file to df\n",
        "    EEG_data.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append(4) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GktOKHMAHL6m",
        "outputId": "f8abae95-9801-4871-9c28-2300976b5c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1238/1238 [00:30<00:00, 40.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(filenames_listNP):\n",
        "    temp_df = pd.read_csv('./drive/MyDrive/DatasetEEG/NP/' + file_name) ## read from the file to df\n",
        "    EEG_data.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXpsqPi7HPUA",
        "outputId": "f15ced04-c3b4-40d9-eca3-996de80f201e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1264/1264 [00:31<00:00, 40.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(filenames_listNU):\n",
        "    temp_df = pd.read_csv('./drive/MyDrive/DatasetEEG/NU/' + file_name) ## read from the file to df\n",
        "    EEG_data.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append(6) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIydn4iHUrO",
        "outputId": "a093c93c-9d16-4bda-b0dc-85527a66583d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1218/1218 [00:30<00:00, 40.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_test = np.array(y_train_test)\n",
        "EEG_data = np.array(EEG_data)"
      ],
      "metadata": {
        "id": "rIZTQY6QHb_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_test.shape)\n",
        "print(EEG_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp8lzy6nHe6x",
        "outputId": "04be229f-d71c-40e9-b74c-6347a16ae4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16669,)\n",
            "(16669, 63, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "NBIkyVZkHkev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_val, x_test, y_train_val, y_test  = train_test_split(EEG_data, y_train_test, test_size=0.10, random_state=42)"
      ],
      "metadata": {
        "id": "AUg13pJFHvJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_test = train_test_split(x_train_val, y_train_val, test_size=0.09, random_state=42)"
      ],
      "metadata": {
        "id": "ogZzu49sHwUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eNB2KQNH2bc",
        "outputId": "41bfa05f-2540-4d82-a29d-a13f68b7389c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13651, 63, 384)\n",
            "(1667, 63, 384)\n",
            "(1351, 63, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pip install Keras-Applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTVXJ4qWIALS",
        "outputId": "2d22c283-1592-491f-ddab-9c6337f16933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras-Applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from random import randint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "plt.style.use('seaborn-white')\n",
        "import seaborn as sns\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage.transform import resize\n",
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
        "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
        "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
        "from tqdm import tqdm_notebook\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.utils import conv_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "\n",
        "from keras import backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from keras.engine.training import Model\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers.core import Activation, SpatialDropout2D\n",
        "from keras.layers.merge import concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D"
      ],
      "metadata": {
        "id": "3m40rrmVIDm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block_simple(prevlayer, filters, prefix, strides=(1, 1)):\n",
        "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides, name=prefix + \"_conv\")(prevlayer)\n",
        "    conv = BatchNormalization(name=prefix + \"_bn\")(conv)\n",
        "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
        "    return conv\n",
        "\n",
        "def conv_block_simple_no_bn(prevlayer, filters, prefix, strides=(1, 1)):\n",
        "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides, name=prefix + \"_conv\")(prevlayer)\n",
        "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
        "    return conv"
      ],
      "metadata": {
        "id": "kOUPzTwJISs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "def get_unet_resnet(input_shape):\n",
        "    resnet_base = ResNet50(input_shape=input_shape, include_top=False)\n",
        "    return resnet_base"
      ],
      "metadata": {
        "id": "yvdxbCm0IZx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.layers import Input\n",
        "from keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file"
      ],
      "metadata": {
        "id": "PhEg8gAvIhFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'keras.., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size,\n",
        "               padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"A block that has a conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'keras.., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
        "    And the shortcut should have strides=(2,2) as well\n",
        "    \"\"\"\n",
        "    filters1, filters2, filters3 = filters\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Conv2D(filters1, (1, 1), strides=strides,\n",
        "               name=conv_name_base + '2a')(input_tensor)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters2, kernel_size, padding='same',\n",
        "               name=conv_name_base + '2b')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n",
        "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
        "                      name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "GDbpxDkGIp6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(include_top=True, weights='imagenet',\n",
        "             input_tensor=None, input_shape=None,\n",
        "             pooling=None,\n",
        "             classes=1000):\n",
        "    if weights not in {'imagenet', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `imagenet` '\n",
        "                         '(pre-training on ImageNet).')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)\n",
        "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='d')\n",
        "#     x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
        "\n",
        "#     if include_top:\n",
        "#         x = Flatten()(x)\n",
        "#         x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
        "#     else:\n",
        "#         if pooling == 'avg':\n",
        "#             x = GlobalAveragePooling2D()(x)\n",
        "#         elif pooling == 'max':\n",
        "#             x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='resnet50')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                                    WEIGHTS_PATH,\n",
        "                                    cache_subdir='models',\n",
        "                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
        "        else:\n",
        "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                                    WEIGHTS_PATH_NO_TOP,\n",
        "                                    cache_subdir='models',\n",
        "                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n",
        "        model.load_weights(weights_path,by_name=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "u39kZzrkI2mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu6(x):\n",
        "    return K.relu(x, max_value=6)"
      ],
      "metadata": {
        "id": "lDd6blxiI5-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_iou_vector(A, B):\n",
        "    batch_size = A.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch]>0, B[batch]>0        \n",
        "        intersection = np.logical_and(t, p)\n",
        "        union = np.logical_or(t, p)\n",
        "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
        "        thresholds = np.arange(0.5, 1, 0.05)\n",
        "        s = []\n",
        "        for thresh in thresholds:\n",
        "            s.append(iou > thresh)\n",
        "        metric.append(np.mean(s))\n",
        "\n",
        "    return np.mean(metric)\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "metadata": {
        "id": "dVf328vPI9tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "def weighted_bce_loss(y_true, y_pred, weight):\n",
        "    epsilon = 1e-7\n",
        "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
        "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
        "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
        "    return K.sum(loss) / K.sum(weight)\n",
        "\n",
        "def weighted_dice_loss(y_true, y_pred, weight):\n",
        "    smooth = 1.\n",
        "    w, m1, m2 = weight, y_true, y_pred\n",
        "    intersection = (m1 * m2)\n",
        "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
        "    loss = 1. - K.sum(score)\n",
        "    return loss\n",
        "\n",
        "def weighted_bce_dice_loss(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    # if we want to get same size of output, kernel size must be odd\n",
        "    averaged_mask = K.pool2d(\n",
        "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
        "    weight = K.ones_like(averaged_mask)\n",
        "    w0 = K.sum(weight)\n",
        "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
        "    w1 = K.sum(weight)\n",
        "    weight *= (w0 / w1)\n",
        "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "_Tt-eMcVJFx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.enable()"
      ],
      "metadata": {
        "id": "WB35apuyJZxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = get_unet_resnet(input_shape=(63, 384, 3))"
      ],
      "metadata": {
        "id": "9gUhPsakJeHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=bce_dice_loss, optimizer='adam', metrics=[my_iou_metric])"
      ],
      "metadata": {
        "id": "IfcWYaVqJi8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
        "batch_size = 86\n",
        "history =model.fit(x_train, y_train, epochs=50, batch_size=86, verbose=1, validation_split=0.09)"
      ],
      "metadata": {
        "id": "wFuRiUq-JkGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "c5f85f65-a1d1-4d35-ff74-02eb3ba4a7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 63, 384, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 63, 384, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 63, 384).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e030686c3794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# Turn epochs to 30 to get 0.9967 accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m86\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.09\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"resnet50\" (type Functional).\n    \n    Input 0 of layer \"conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 63, 384)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 63, 384), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    }
  ]
}